import os
import math
import re
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
import matplotlib.pyplot as plt
from tqdm import tqdm
from torchvision import models
import numpy as np

# å¼•å…¥å°ˆæ¡ˆæ¨¡çµ„
from src.networks import EdgeGenerator, DiffusionUNet, Discriminator, VGGLoss
from src.diffusion import DiffusionManager
from src.dataset import InpaintingDataset
from src.utils import manual_ssim, save_preview_image

# ================= CONFIG (å¤šå¡ä¸¦è¡Œèˆ‡ç©©å®šæ€§å„ªåŒ–) =================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
BATCH_SIZE = 4           # æ¯å¼µé¡¯å¡çš„ Batch Size
ACCUMULATION_STEPS = 4  # å¯¦è³ªç­‰æ•ˆ Batch Size = 4 * 2(GPUs) * 12 = 96
EPOCHS = 200
PURE_EPOCHS = 50         # å‰ 50 Epoch ç´”åƒç´ å°é½Šï¼Œä¸è·‘ VGG
BASE_LR = 1e-5           # é™ä½ LR ä»¥é˜²æ­¢ Epoch 30 å´©æ½°
SAVE_DIR = "checkpoints_stage2_v13_ultimate"
SAMPLE_DIR = "samples_stage2_v13_ultimate"
LOG_DIR = "runs/stage2_v13_ultimate"
G1_CHECKPOINT = "./checkpoints_sa/G1_latest.pth"
W_ADV_FINAL = 0.005      # 150 Epoch å¾Œçš„å°æŠ—æå¤±æ¬Šé‡


# [çºŒç·´èˆ‡æœ€ä½³åŒ–ç´€éŒ„]
START_EPOCH = 0
LOAD_G2_PATH = None      # å¾é ­é–‹å§‹å»ºè­°è¨­ç‚º Noneï¼Œæˆ–æŒ‡å®šä¹‹å‰çš„ç©©å®šæ¬Šé‡
best_psnr = 0.0          # åˆå§‹åŒ–æœ€ä½³ PSNR ç´€éŒ„

LOAD_G2_PATH = f"checkpoints_stage2_v13_sa/G2_v13_sa_latest.pth"


def get_sa_config(epoch):
    if epoch < PURE_EPOCHS:
        # [éšæ®µä¸€ï¼šçµæ§‹ç©©å›ºæœŸ]
        # è®“ lr ä¿æŒç©©å®šï¼Œw_recon ç·šæ€§å¾ 1.0 çˆ¬å‡åˆ° 2.0ï¼Œw_mse å¾®é™è‡³ 0.8
        ratio = epoch / PURE_EPOCHS
        lr = BASE_LR
        w_recon = 1.0 + 0.5 *(1 - math.cos(math.pi * ratio))  # å¹³æ»‘å¢åŠ 
        w_mse = 1.0 - 0.2 * (1 - math.cos(math.pi * ratio))    # å¹³æ»‘å¾®é™
        w_vgg = 0.01                   # ä¿æŒä½ VGG å£“åˆ¶å½©å™ª
        w_adv = 0.0

    elif epoch < 150:
        # [éšæ®µäºŒï¼šæ·±åº¦æ„ŸçŸ¥å¼·åŒ–æœŸ]
        # é€™è£¡çš„èµ·é»å¿…é ˆå°æ¥éšæ®µä¸€çš„çµ‚é» (w_recon=2.0, w_mse=0.8, w_vgg=0.01)
        eta = (epoch - PURE_EPOCHS) / 100
        alpha = 0.5 * (1 - math.cos(math.pi * eta)) # é¤˜å¼¦å¹³æ»‘ä¿‚æ•¸ (0 -> 1)

        # å­¸ç¿’ç‡é€€ç«
        lr = BASE_LR * 0.5 * (1 + math.cos(math.pi * eta))

        # æ¬Šé‡å¹³æ»‘éæ¸¡
        w_mse = 0.8 * (1 - alpha) + 0.2 * alpha    # 0.8 é™è‡³ 0.2
        w_recon = 2.0 * (1 - alpha) + 1.0 * alpha  # 2.0 é™è‡³ 1.0 (é‡‹æ”¾è‡ªç”±åº¦çµ¦ VGG)
        w_vgg = 0.01 * (1 - alpha) + 0.15 * alpha  # 0.01 å‡è‡³ 0.15
        w_adv = 0.0

    else:
        # [éšæ®µä¸‰ï¼šGAN æ‹‹å…‰æœŸ]
        lr = BASE_LR * 0.1
        w_recon, w_vgg, w_mse = 1.0, 0.2, 0.1
        w_adv = W_ADV_FINAL # 0.005

    return w_recon, w_vgg, w_mse, w_adv, lr
"""
def get_sa_config(epoch):

    get_sa_config çš„ Docstring

    :param epoch: èªªæ˜
    return: recon_w, vgg_w, mse_w, adv_w, lr
    1-50 Epoch: ç´”åƒç´ å°é½ŠæœŸ
    51-200 Epoch: æ·±åº¦æ„ŸçŸ¥å¼·åŒ–æœŸ (ä¸è·‘ GAN)
    201-250 Epoch: çµ‚æ¥µ GAN æ‹‹å…‰éšæ®µ
    é€éé¤˜å¼¦é€€ç«èª¿æ•´å­¸ç¿’ç‡èˆ‡ Loss æ¬Š

    lr = BASE_LR
    # é è¨­å€¼

    if epoch < PURE_EPOCHS:
        w_recon, w_vgg, w_mse, w_adv = 10.0, 0.05, 1.0, 0.0

    elif PURE_EPOCHS <= epoch < 150:
        eta = (epoch - PURE_EPOCHS) / 100
        alpha = 0.5 * (1 - math.cos(math.pi * eta))
        w_mse = 1.0 * (1 - alpha) + 0.1 * alpha
        w_recon = 0.1 * (1 - alpha) + 1.0 * alpha
        w_vgg = 0.05 * (1 - alpha) + 0.2 * alpha
        lr = BASE_LR * 0.5 * (1 + math.cos(math.pi * eta))
        w_adv = 0.0
    # else:
    #     # Epoch 150 ä¹‹å¾Œé€²å…¥æ‹‹å…‰éšæ®µ
    #     # w_mse, w_recon, w_vgg = 0.1, 1.0, 0.2
    #     # lr = BASE_LR * 0.1
    #     eta = (epoch - PURE_EPOCHS) / 100
    #     alpha = 0.5 * (1 - math.cos(math.pi * eta))
    #     w_mse = 1.0 * (1 - alpha) + 0.1 * alpha
    #     w_recon = 0.1 * (1 - alpha) + 1.0 * alpha
    #     w_vgg = 0.05 * (1 - alpha) + 0.2 * alpha
    #     lr = BASE_LR * 0.5 * (1 + math.cos(math.pi * eta))
    #     # w_adv = 0.0
    #     w_adv = 0.005

    return w_recon, w_vgg, w_mse, w_adv, lr
"""

"""
def get_sa_config(epoch):
    #å‹•æ…‹èª¿æ•´å„éšæ®µ Loss æ¬Šé‡èˆ‡å­¸ç¿’ç‡
    if epoch < PURE_EPOCHS:
        return 10.0, 0.0, 1.0, 0.0, BASE_LR # Recon, VGG, MSE, Adv, LR
    elif epoch < 150:
        progress = (epoch - PURE_EPOCHS) / (150 - PURE_EPOCHS)
        cos_val = 0.5 * (1 - math.cos(progress * math.pi))
        lr = 5e-6 + (BASE_LR - 5e-6) * (1 - cos_val)
        vgg_w = 0.05 * cos_val
        recon_w = 5.0 + (10.0 * cos_val)
        return recon_w, vgg_w, 1.0, 0.0, lr
    else:
        # 150 Epoch å¾Œé€²å…¥çµ‚æ¥µ GAN æ‹‹å…‰éšæ®µ
        return 15.0, 0.005, 0.5, W_ADV_FINAL, 5e-6
    """







# ================= ä¸»è¨“ç·´é‚è¼¯ =================
def train():
    global best_psnr
    os.makedirs(SAVE_DIR, exist_ok=True); os.makedirs(SAMPLE_DIR, exist_ok=True)
    writer = SummaryWriter(LOG_DIR)

    train_loader = DataLoader(InpaintingDataset("./datasets/img", mode='train'),
                              batch_size=BATCH_SIZE, shuffle=True, num_workers=12, pin_memory=True)

    G1 = EdgeGenerator().to(DEVICE).eval()
    G1.load_state_dict(torch.load(G1_CHECKPOINT, map_location=DEVICE))

    G2 = DiffusionUNet(in_channels=8, out_channels=3).to(DEVICE)
    D = Discriminator().to(DEVICE)

    opt_G = optim.AdamW(G2.parameters(), lr=BASE_LR, weight_decay=1e-4)
    opt_D = optim.AdamW(D.parameters(), lr=1e-4, weight_decay=1e-4)
    scaler_G = torch.amp.GradScaler('cuda')
    scaler_D = torch.amp.GradScaler('cuda')

    # åŠ è¼‰é‚è¼¯
    if LOAD_G2_PATH and os.path.exists(LOAD_G2_PATH):
        checkpoint = torch.load(LOAD_G2_PATH, map_location=DEVICE)
        G2.load_state_dict(checkpoint['model_state_dict'])
        if 'optimizer_state_dict' in checkpoint:
            opt_G.load_state_dict(checkpoint['optimizer_state_dict'])
        print(f"[*] æˆåŠŸè¼‰å…¥æª¢æŸ¥é»")

    if torch.cuda.device_count() > 1:
        G2 = nn.DataParallel(G2); D = nn.DataParallel(D)

    diffusion = DiffusionManager(device=DEVICE)
    vgg_criterion = VGGLoss(DEVICE)

    for epoch in range(START_EPOCH, EPOCHS):
        epoch_l1, epoch_vgg, epoch_mse, epoch_adv = 0.0, 0.0, 0.0, 0.0
        w_recon, w_vgg, w_mse, w_adv, curr_lr = get_sa_config(epoch)
        for param_group in opt_G.param_groups: param_group['lr'] = curr_lr

        G2.train(); D.train()
        pbar = tqdm(train_loader, desc=f"Epoch {epoch}")

        for i, (imgs, _, masks) in enumerate(pbar):
            imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)

            with torch.amp.autocast('cuda'):
                with torch.no_grad():
                    pred_edges = G1(torch.cat([imgs * (1 - masks), masks], dim=1))

                condition = torch.cat([imgs * (1 - masks), masks, pred_edges], dim=1)
                t = diffusion.sample_timesteps(imgs.shape[0]).to(DEVICE)
                x_t, noise = diffusion.noise_images(imgs, t)

                # [ğŸš€ é˜²ç¦¦ 1] é™åˆ¶é æ¸¬å™ªè²ç¯„åœ
                pred_noise = G2(x_t, t, condition)
                pred_noise = torch.clamp(torch.nan_to_num(pred_noise), -1, 1.0)
                pred_noise = pred_noise.mean(1, keepdim=True).repeat(1, 3, 1, 1)  # å¼·åˆ¶å¹³å‡é€šé“ï¼Œé˜²æ­¢è‰²å

                l_mse = F.mse_loss(pred_noise, noise)

                # [ğŸš€ é˜²ç¦¦ 2] ç©©å®šåˆ†æ¯ï¼Œå¾¹åº•è§£æ±ºé–‹å±€å½©é»
                alpha_hat_t = diffusion.alpha_hat[t][:, None, None, None]

                # denom = torch.sqrt(alpha_hat_t).clamp(min=0.35)+ 1e-6
                denom = torch.sqrt(alpha_hat_t + 1e-7)
                pred_x0 = (x_t - torch.sqrt(1 - alpha_hat_t) * pred_noise) / denom


                # [ğŸš€ é˜²ç¦¦ 3] åš´æ ¼æˆªæ–·åƒç´ ç¯„åœ
                pred_x0 = torch.clamp(torch.nan_to_num(pred_x0), -1.0, 1.0)

                l_pixel = F.l1_loss(pred_x0, imgs)
                l_vgg = vgg_criterion(pred_x0, imgs) if (epoch >= PURE_EPOCHS and w_vgg > 0) else torch.tensor(0.0, device=DEVICE)

                # åˆ¤åˆ¥å™¨åšå¼ˆé‚è¼¯
                l_adv_G = torch.tensor(0.0, device=DEVICE)
                if w_adv > 0:
                    opt_D.zero_grad()
                    real_res = D(imgs)
                    fake_res = D(pred_x0.detach())
                    loss_D = (F.relu(1.0 - real_res).mean() + F.relu(1.0 + fake_res).mean()) * 0.5
                    scaler_D.scale(loss_D).backward()
                    scaler_D.step(opt_D); scaler_D.update()
                    l_adv_G = -D(pred_x0).mean()
                safe_pred = torch.clamp(pred_x0, -1.0, 1.0)
                with torch.no_grad():
                    mask_pixel_count = masks.sum(dim=[1, 2, 3]).clamp(min=1.0)

                pred_x0: torch.Tensor = pred_x0.mean(dim=1, keepdim=True).repeat(1, 3, 1, 1)
                mask_safe = masks.sum(dim=[1, 2, 3]).clamp(min=1.0).view(-1, 1)
                pred_mask_mean = (pred_x0 * masks).sum(dim=[2, 3]) /mask_safe
                gt_mask_mean = (imgs * masks).sum(dim=[2, 3]) / mask_safe
# è¨ˆç®—å±€éƒ¨ Color Loss
                l_color = F.mse_loss(pred_mask_mean, gt_mask_mean)
                loss_total = (l_mse * w_mse + l_vgg * w_vgg + l_pixel * w_recon + l_adv_G * w_adv + l_color * 0.1)/ ACCUMULATION_STEPS

            if torch.isnan(loss_total):
                print(f"[âš ï¸] NaN loss detected at epoch {epoch}, step {i}")
                continue
            scaler_G.scale(loss_total).backward()

            if (i + 1) % ACCUMULATION_STEPS == 0:
                scaler_G.unscale_(opt_G)
                torch.nn.utils.clip_grad_norm_(G2.parameters(),0.3)
                scaler_G.step(opt_G); scaler_G.update(); opt_G.zero_grad()
                epoch_l1 += l_pixel.item(); epoch_mse += l_mse.item(); epoch_vgg += l_vgg.item()


            if i % 10 == 0:
                with torch.no_grad():
                    psnr_cur = 20 * math.log10(1.0 / (torch.sqrt(F.mse_loss((pred_x0.detach()+1)/2, (imgs+1)/2)) + 1e-9))
                pbar.set_postfix({"L1": f"{l_pixel.item():.4f}", "PSNR": f"{psnr_cur:.2f}"})



        # --- ä¿å­˜èˆ‡é è¦½ ---
        # --- Epoch çµå°¾ç´€éŒ„ TensorBoard ---
        avg_steps = len(train_loader) // ACCUMULATION_STEPS
        writer.add_scalar("Loss_Detail/Pixel_L1", epoch_l1 / avg_steps, epoch)
        writer.add_scalar("Loss_Detail/VGG_Perceptual", epoch_vgg / avg_steps, epoch)
        writer.add_scalar("Params/Learning_Rate", curr_lr, epoch)

        G2.eval()
        with torch.no_grad():
            m_sam = G2.module if hasattr(G2, 'module') else G2

            # [ğŸš€ æ ¸å¿ƒåŠŸèƒ½] è‡ªå‹•ç”Ÿæˆ Baseline (Epoch 149)
            if epoch == 149:
                print("[*] ç”Ÿæˆ No-GAN Baseline...")
                os.makedirs("baseline_samples", exist_ok=True)
                baseline_res = diffusion.sample(m_sam, condition[0:4], n=4, steps=100)
                save_preview_image(imgs[0:4], masks[0:4], pred_edges[0:4], baseline_res, 0.0, epoch, "baseline_samples")

            samples = diffusion.sample(m_sam, condition[0:1], n=1, steps=50)
            res_img = (imgs[0:1] * (1 - masks[0:1])) + (samples * masks[0:1])
            v_psnr = 20 * math.log10(1.0 / (torch.sqrt(F.mse_loss((res_img+1)/2, (imgs[0:1]+1)/2)) + 1e-8))
            v_ssim = manual_ssim((res_img+1)/2, (imgs[0:1]+1)/2).item()

             # [â­] æœ€ä½³åŒ–ç´€éŒ„é»
            if v_psnr > best_psnr:
                best_psnr = v_psnr
                torch.save(m_sam.state_dict(), f"{SAVE_DIR}/G2_BEST_PSNR_ep{epoch}.pth")
                # åŒæ™‚è¦†è“‹ä¸€å€‹ä¸å¸¶ epoch æ¨™ç±¤çš„æ–¹ä¾¿æ¸¬è©¦
                torch.save(m_sam.state_dict(), f"{SAVE_DIR}/G2_BEST_PSNR_latest.pth")
                print(f"\n[ğŸ†] çªç ´ç´€éŒ„! Epoch {epoch} PSNR: {best_psnr:.2f}. æœ€ä½³æ¬Šé‡å·²å‚™ä»½ã€‚")

            # ç´€éŒ„æŒ‡æ¨™
            writer.add_scalar("Metrics/PSNR", v_psnr, epoch)
            writer.add_scalar("Metrics/SSIM", v_ssim, epoch)
            writer.add_image("Preview/Epoch_Res", (res_img[0]+1)/2, epoch)

            # ç´€éŒ„æå¤± (ç¢ºä¿è®Šæ•¸å­˜åœ¨ä¸”åç¨±æ­£ç¢º)
          # ç´€éŒ„æå¤± (ç¢ºä¿è®Šæ•¸å­˜åœ¨ä¸”åç¨±æ­£ç¢º)
            avg_steps = len(train_loader) // ACCUMULATION_STEPS
            if avg_steps > 0:
                writer.add_scalar("Losses/L1_Loss", epoch_l1 / avg_steps, epoch)
                writer.add_scalar("Losses/VGG_Loss", epoch_vgg / avg_steps, epoch)
                writer.add_scalar("Losses/MSE_Loss", epoch_mse / avg_steps, epoch)
                writer.add_scalar("Losses/Adv_Loss", float(l_adv_G.item()), epoch)

                writer.add_scalar("Losses/Total_Loss", float(loss_total.item()), epoch)
                writer.add_scalar("Weights/w_recon", w_recon, epoch)
                writer.add_scalar("Weights/w_vgg", w_vgg, epoch)
                writer.add_scalar("Weights/w_mse", w_mse, epoch)
                writer.add_scalar("Weights/w_adv", w_adv, epoch)
                writer.add_scalar("Params/Learning_Rate", curr_lr, epoch)
            # å„²å­˜ PNG é è¦½åœ–
            save_preview_image(imgs, masks, pred_edges, res_img, v_psnr, epoch, SAMPLE_DIR)

        # ä¿å­˜å®Œæ•´å­—å…¸
        torch.save({
            'epoch': epoch,
            'model_state_dict': m_sam.state_dict(),
            'optimizer_state_dict': opt_G.state_dict(),
            'scaler_state_dict': scaler_G.state_dict(),
            'best_psnr': best_psnr,
        }, f"{SAVE_DIR}/checkpoint_latest.pth")

    writer.close()

if __name__ == "__main__": train()
